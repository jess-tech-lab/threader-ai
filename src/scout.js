#!/usr/bin/env node
/**
 * Threader AI - Terminal Scout
 *
 * Dynamic CLI tool for analyzing company feedback from Reddit
 * Usage: npm run scout "CompanyName" [--tenant tenantId]
 *
 * Flow: Scrape subreddits â†’ Analyze with LLM â†’ Run Strategic Synthesizer â†’ Save to Supabase
 */

import { smartScrape } from './scrapers/redditScraper.js';
import { classifyFeedbackBatch, generateExecutiveSummary } from './analysis/classifier.js';
import { synthesizeFeedback, formatSynthesisReport } from './analysis/synthesizer.js';
import {
  supabaseAdmin,
  insertFeedbackItems,
  getOrCreateCompany,
  createScrapeJob,
  updateScrapeJob,
} from './db/supabase.js';
import dotenv from 'dotenv';
import fs from 'fs';
import path from 'path';
import { fileURLToPath } from 'url';

dotenv.config();

const __filename = fileURLToPath(import.meta.url);
const __dirname = path.dirname(__filename);

// Default tenant ID for terminal runs
const DEFAULT_TENANT_ID = 'system_admin';

/**
 * Parse CLI arguments
 * Supports: npm run scout "CompanyName" --tenant "tenantId"
 */
function parseArgs() {
  const args = process.argv.slice(2);
  const result = {
    companyName: null,
    tenantId: DEFAULT_TENANT_ID,
    help: false,
  };

  for (let i = 0; i < args.length; i++) {
    const arg = args[i];

    if (arg === '--help' || arg === '-h') {
      result.help = true;
    } else if (arg === '--tenant' || arg === '-t') {
      result.tenantId = args[++i];
    } else if (!arg.startsWith('-')) {
      result.companyName = arg;
    }
  }

  return result;
}

/**
 * Print help message
 */
function printHelp() {
  console.log(`
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                  Threader AI - Terminal Scout                  â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘  Analyze company feedback from Reddit using AI                 â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

Usage:
  npm run scout <company_name> [options]

Arguments:
  company_name     Name of the company to analyze (required)

Options:
  --tenant, -t     Tenant ID for multi-tenancy (default: system_admin)
  --help, -h       Show this help message

Examples:
  npm run scout "Notion"
  npm run scout "Linear" --tenant "my-org-123"
  npm run scout "Figma" -t "design-team"

Environment Variables:
  OPENAI_API_KEY           Required for LLM analysis
  SUPABASE_URL             Required for database storage
  SUPABASE_SERVICE_ROLE_KEY  Required for bypassing RLS

Pipeline Steps:
  1. Smart Scrape    - Discover relevant subreddits and fetch posts
  2. Classification  - Analyze feedback with Senior PM perspective
  3. Synthesis       - Generate strategic insights and OKRs
  4. Storage         - Save snapshot to Supabase
`);
}

/**
 * Save synthesis to local file (fallback when Supabase isn't configured)
 * This writes directly to frontend/public/demo-config.json for immediate access
 */
function saveToLocalFile(companyName, synthesis, metadata = {}) {
  const demoConfigPath = path.join(__dirname, '../frontend/public/demo-config.json');

  const config = {
    companyName,
    synthesis,
    metadata: {
      ...metadata,
      created_by: 'terminal_scout',
      version: '2.0',
    },
    lastUpdated: new Date().toISOString(),
    note: 'Auto-generated by scout command. Frontend will load this when ?company matches.',
  };

  fs.writeFileSync(demoConfigPath, JSON.stringify(config, null, 2));

  console.log(`\n[Scout] ğŸ“ Saved to local file: ${demoConfigPath}`);
  console.log(`[Scout]    Company: ${companyName}`);
  console.log(`[Scout]    File size: ${(JSON.stringify(config).length / 1024).toFixed(1)} KB`);

  return config;
}

/**
 * Save synthesis snapshot to Supabase AND local file
 * Returns the UUID for shareable URL
 * @param {string} tenantId - Tenant ID
 * @param {string} companyId - Company ID
 * @param {string} companyName - Company name (for frontend lookup)
 * @param {Object} synthesis - The strategic synthesis object
 * @param {Object} metadata - Additional metadata
 * @returns {Object} - { uuid, localResult }
 */
async function saveSnapshot(tenantId, companyId, companyName, synthesis, metadata = {}) {
  // ALWAYS save to local file first (works without Supabase)
  console.log(`\n[Scout] ğŸ’¾ Saving snapshot for: ${companyName}`);

  const localResult = saveToLocalFile(companyName, synthesis, metadata);
  let reportUuid = null;

  // If Supabase is configured, also save there
  if (supabaseAdmin) {
    console.log(`[Scout]    Also saving to Supabase...`);

    // Use the new schema with report_data
    const snapshot = {
      company_name: companyName,
      report_data: synthesis,
      is_public: true,
      tenant_id: tenantId || 'public',
    };

    try {
      const { data, error } = await supabaseAdmin
        .from('snapshots')
        .insert(snapshot)
        .select('id, created_at')
        .single();

      if (error) {
        if (error.code === '42P01') {
          console.warn('[Scout] âš ï¸  Supabase snapshots table does not exist');
          console.warn('[Scout]    Run the migration: supabase/migrations/001_create_snapshots_table.sql');
        } else {
          console.warn(`[Scout] âš ï¸  Supabase save failed: ${error.message}`);
        }
        console.log(`[Scout]    Local file will be used as fallback`);
      } else {
        reportUuid = data.id;
        console.log(`[Scout] âœ… Saved to Supabase`);
        console.log(`[Scout]    UUID: ${reportUuid}`);
        console.log(`[Scout]    Created: ${data.created_at}`);
      }
    } catch (err) {
      console.warn(`[Scout] âš ï¸  Supabase error: ${err.message}`);
      console.log(`[Scout]    Local file will be used as fallback`);
    }
  } else {
    console.log(`[Scout]    Supabase not configured - using local file only`);
  }

  // Print shareable URLs
  console.log(`\n[Scout] ğŸ”— Report URLs:`);
  if (reportUuid) {
    console.log(`[Scout]    ğŸ“Œ Secure URL (UUID): http://localhost:5173/report/${reportUuid}`);
  }
  console.log(`[Scout]    ğŸ“ Legacy URL (name): http://localhost:5173/?company=${encodeURIComponent(companyName)}`);
  console.log(`[Scout] âœ… Report ready! Open a URL above in your browser.`);

  return { uuid: reportUuid, localResult };
}

/**
 * Create snapshots table if it doesn't exist
 * This is a fallback - ideally the table should be created via migrations
 */
async function createSnapshotsTable() {
  if (!supabaseAdmin) return;

  // Using raw SQL via RPC (requires a function in Supabase)
  // For now, just log instructions
  console.log(`
[Scout] To create the snapshots table, run this SQL in Supabase:

CREATE TABLE IF NOT EXISTS public.snapshots (
  id UUID DEFAULT gen_random_uuid() PRIMARY KEY,
  tenant_id TEXT NOT NULL,
  company_id UUID REFERENCES monitored_companies(id),
  company_name TEXT NOT NULL,
  is_public BOOLEAN DEFAULT false,
  synthesis_data JSONB NOT NULL,
  metadata JSONB DEFAULT '{}',
  created_at TIMESTAMPTZ DEFAULT NOW()
);

-- Enable RLS
ALTER TABLE public.snapshots ENABLE ROW LEVEL SECURITY;

-- RLS Policy: Users can only see their own tenant's snapshots
CREATE POLICY "tenant_isolation" ON public.snapshots
  FOR ALL USING (tenant_id = current_setting('app.tenant_id', true));

-- RLS Policy: Allow public access to is_public=true snapshots
CREATE POLICY "public_demo_access" ON public.snapshots
  FOR SELECT USING (is_public = true);

-- Index for fast lookups
CREATE INDEX idx_snapshots_tenant_company ON public.snapshots(tenant_id, company_id);
CREATE INDEX idx_snapshots_company_name ON public.snapshots(company_name);
CREATE INDEX idx_snapshots_public ON public.snapshots(is_public) WHERE is_public = true;
CREATE INDEX idx_snapshots_created_at ON public.snapshots(created_at DESC);
`);
}

/**
 * Main scout function
 */
async function scout(companyName, tenantId) {
  console.log(`
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                  Threader AI - Terminal Scout                  â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘  Company: ${companyName.padEnd(50)}â•‘
â•‘  Tenant:  ${tenantId.padEnd(50)}â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
`);

  const startTime = Date.now();
  const results = {
    companyName,
    tenantId,
    scrapeResults: null,
    classificationResults: null,
    executiveSummary: null,
    strategicSynthesis: null,
    snapshot: null,
    errors: [],
  };

  // Get or create company record
  let company = null;
  if (supabaseAdmin) {
    try {
      company = await getOrCreateCompany(tenantId, companyName);
      console.log(`[Scout] Company ID: ${company.id}`);
    } catch (error) {
      console.warn('[Scout] Could not create company record:', error.message);
    }
  }

  // Step 1: Smart Scrape
  console.log('\nâ”Œâ”€ Step 1: Smart Scraping â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”');
  let job = null;
  try {
    if (company && supabaseAdmin) {
      job = await createScrapeJob(tenantId, company.id, 'reddit');
    }

    const scrapeResults = await smartScrape(companyName, {
      maxItemsPerSubreddit: 50,
    });

    results.scrapeResults = scrapeResults;

    if (job) {
      await updateScrapeJob(job.id, {
        items_found: scrapeResults.mentions.length,
        status: 'completed',
        completed_at: new Date().toISOString(),
      });
    }

    console.log(`â””â”€ Scraped ${scrapeResults.mentions.length} posts from ${scrapeResults.subredditsSearched?.length || 0} subreddits`);
  } catch (error) {
    console.error('â””â”€ Scraping error:', error.message);
    results.errors.push({ step: 'scraping', error: error.message });

    if (job) {
      await updateScrapeJob(job.id, {
        status: 'failed',
        error_message: error.message,
        completed_at: new Date().toISOString(),
      });
    }
  }

  // Step 2: Classification
  if (results.scrapeResults?.mentions?.length > 0) {
    console.log('\nâ”Œâ”€ Step 2: AI Classification â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”');
    try {
      const classificationResults = await classifyFeedbackBatch(
        results.scrapeResults.mentions,
        { batchSize: 5 }
      );

      results.classificationResults = classificationResults;
      results.executiveSummary = generateExecutiveSummary(classificationResults, companyName);

      console.log(`â”‚  Constructive: ${classificationResults.stats.constructive}`);
      console.log(`â”‚  Praise:       ${classificationResults.stats.praise}`);
      console.log(`â”‚  Neutral:      ${classificationResults.stats.neutral}`);
      console.log(`â””â”€ Classification complete`);
    } catch (error) {
      console.error('â””â”€ Classification error:', error.message);
      results.errors.push({ step: 'classification', error: error.message });
    }
  } else {
    console.log('\nâ”Œâ”€ Step 2: AI Classification â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”');
    console.log('â””â”€ Skipped (no items to classify)');
  }

  // Step 3: Strategic Synthesis
  if (results.classificationResults?.items?.length >= 5) {
    console.log('\nâ”Œâ”€ Step 3: Strategic Synthesis â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”');
    try {
      const synthesis = await synthesizeFeedback(
        results.classificationResults.items,
        companyName
      );

      results.strategicSynthesis = synthesis;
      console.log('â””â”€ Strategic synthesis complete');
    } catch (error) {
      console.error('â””â”€ Synthesis error:', error.message);
      results.errors.push({ step: 'synthesis', error: error.message });
    }
  } else {
    console.log('\nâ”Œâ”€ Step 3: Strategic Synthesis â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”');
    console.log('â””â”€ Skipped (need at least 5 classified items)');
  }

  // Step 4: Save Results (Local file + optional Supabase)
  console.log('\nâ”Œâ”€ Step 4: Save Results â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”');

  // ALWAYS save to local file if we have synthesis data
  let reportUuid = null;
  if (results.strategicSynthesis) {
    try {
      const saveResult = await saveSnapshot(
        tenantId,
        company?.id || null,
        companyName,
        results.strategicSynthesis,
        {
          totalAnalyzed: results.classificationResults?.items?.length || 0,
          dataSources: ['reddit'],
          subredditsSearched: results.scrapeResults?.subredditsSearched || [],
        }
      );
      results.snapshot = saveResult.localResult;
      reportUuid = saveResult.uuid;
      console.log('â”‚  âœ… Synthesis saved');
    } catch (error) {
      console.error('â”‚  âŒ Save error:', error.message);
      results.errors.push({ step: 'save', error: error.message });
    }
  } else {
    console.log('â”‚  âš ï¸  No synthesis data to save');
  }

  // Optionally store to Supabase if configured
  if (company && supabaseAdmin && results.classificationResults) {
    try {
      const itemsToStore = results.classificationResults.items.map(item => ({
        ...results.scrapeResults.mentions.find(m => m.sourceId === item.sourceId),
        classification: item,
      }));

      await insertFeedbackItems(tenantId, company.id, itemsToStore);
      console.log(`â”‚  âœ… Stored ${itemsToStore.length} items to Supabase`);
    } catch (error) {
      console.error('â”‚  âš ï¸  Supabase storage error:', error.message);
    }
  }

  console.log('â””â”€ Storage complete');

  // Final Report
  const elapsed = ((Date.now() - startTime) / 1000).toFixed(1);
  console.log(`
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                      Scout Complete                            â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘  Duration: ${(elapsed + 's').padEnd(49)}â•‘
â•‘  Items Analyzed: ${(results.classificationResults?.items?.length || 0).toString().padEnd(43)}â•‘
â•‘  Errors: ${results.errors.length.toString().padEnd(51)}â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
`);

  // Print strategic synthesis
  if (results.strategicSynthesis) {
    console.log(formatSynthesisReport(results.strategicSynthesis, companyName));
  }

  // Print JSON output
  console.log('\nâ”Œâ”€ JSON Output â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”');
  console.log(JSON.stringify({
    metadata: {
      companyName,
      tenantId,
      reportUuid,
      reportUrl: reportUuid ? `http://localhost:5173/report/${reportUuid}` : null,
      legacyUrl: `http://localhost:5173/?company=${encodeURIComponent(companyName)}`,
      analyzedAt: new Date().toISOString(),
      totalItems: results.classificationResults?.items?.length || 0,
    },
    synthesis: results.strategicSynthesis,
    errors: results.errors,
  }, null, 2));

  // Add UUID to results for programmatic access
  results.reportUuid = reportUuid;

  return results;
}

// Main execution
async function main() {
  const args = parseArgs();

  if (args.help) {
    printHelp();
    process.exit(0);
  }

  if (!args.companyName) {
    console.error('Error: Company name is required\n');
    printHelp();
    process.exit(1);
  }

  // Check for required environment variables
  if (!process.env.OPENAI_API_KEY) {
    console.error(`
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                    Configuration Error                         â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘  Missing OPENAI_API_KEY environment variable                   â•‘
â•‘                                                                 â•‘
â•‘  To run the scout:                                              â•‘
â•‘  1. Copy .env.example to .env                                   â•‘
â•‘  2. Add your OpenAI API key                                     â•‘
â•‘  3. Run: npm run scout "CompanyName"                            â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
`);
    process.exit(1);
  }

  try {
    await scout(args.companyName, args.tenantId);
  } catch (error) {
    console.error('Scout failed:', error);
    process.exit(1);
  }
}

main();
